{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perses.analysis.analysis import Analysis\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pymbar\n",
    "%matplotlib inline\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(forward_work, reverse_work, forward_accumulated, reverse_accumulated, dir_num, title, phase, output_dir): \n",
    "    # Substract offset\n",
    "    forward_work_offset = []\n",
    "    for cycle in forward_work:\n",
    "        forward_work_offset.append(np.array([val - cycle[0] for val in cycle[1:]]))\n",
    "    forward_work_offset = np.array(forward_work_offset)\n",
    "\n",
    "    reverse_work_offset = []\n",
    "    for cycle in reverse_work:\n",
    "        reverse_work_offset.append(np.array([val - cycle[0] for val in cycle[1:]]))\n",
    "    reverse_work_offset = np.array(reverse_work_offset)\n",
    "    \n",
    "    # Compute dg, ddg\n",
    "    dg, ddg = pymbar.bar.BAR(forward_accumulated, reverse_accumulated)\n",
    "    \n",
    "    # Plot work trajectories\n",
    "    for cycle in forward_work_offset:\n",
    "        x = [(i+1)*4e-3 for i in range(len(list(cycle)))]\n",
    "        y = cycle\n",
    "        plt.plot(x, y, color=sns.color_palette()[0])\n",
    "    for cycle in reverse_work_offset:\n",
    "        x = [(i+1)*4e-3 for i in range(len(list(cycle)))]\n",
    "        y = -cycle\n",
    "        plt.plot(x, y, color=sns.color_palette()[1])\n",
    "    plt.xlabel(\"$t_{neq}$ (ps)\")\n",
    "    plt.ylabel(\"work (kT)\")\n",
    "    plt.title(title)\n",
    "    plt.savefig(os.path.join(output_dir, f\"{dir_num}_{phase}_work_traj.png\"), dpi=500)\n",
    "    plt.clf()\n",
    "    \n",
    "    # Plot work distributions\n",
    "    accumulated_forward = [cycle[-1] for cycle in forward_work_offset]\n",
    "    accumulated_reverse = [-cycle[-1] for cycle in reverse_work_offset]\n",
    "    sns.distplot(accumulated_forward)\n",
    "    sns.distplot(accumulated_reverse)\n",
    "    plt.axvline(dg)\n",
    "    plt.axvline(dg - ddg, linestyle='dotted')\n",
    "    plt.axvline(dg + ddg, linestyle='dotted')\n",
    "    plt.xlabel(\"work (kT)\")\n",
    "    plt.ylabel(\"p(w)\")\n",
    "    plt.title(title)\n",
    "    plt.savefig(os.path.join(output_dir, f\"{dir_num}_{phase}_work_dist.png\"), dpi=500)\n",
    "    plt.clf()\n",
    "    \n",
    "    # Compute free energy \n",
    "    return dg, ddg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "amino_acids = ['ALA', 'CYS', 'SER', 'THR']\n",
    "\n",
    "# Create list of tuples for every pair of amino acids\n",
    "pairs = list(itertools.permutations(amino_acids, r=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangi/miniconda3/envs/perses-sims/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24de0b47d05e4955bcd2c3ed45ac95e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: 18\n",
      "job: 0\n",
      "job: 1\n",
      "job: 2\n",
      "job: 3\n",
      "job: 4\n",
      "job: 5\n",
      "job: 6\n",
      "job: 7\n",
      "job: 8\n",
      "job: 9\n",
      "job: 10\n",
      "job: 11\n",
      "job: 12\n",
      "job: 13\n",
      "job: 14\n",
      "job: 15\n",
      "job: 16\n",
      "job: 17\n",
      "job: 18\n",
      "job: 19\n",
      "job: 20\n",
      "job: 21\n",
      "job: 22\n",
      "job: 23\n",
      "job: 24\n",
      "job: 25\n",
      "job: 26\n",
      "job: 27\n",
      "job: 28\n",
      "job: 29\n",
      "job: 30\n",
      "job: 31\n",
      "job: 32\n",
      "job: 33\n",
      "job: 34\n",
      "job: 35\n",
      "job: 36\n",
      "job: 37\n",
      "job: 38\n",
      "job: 39\n",
      "job: 40\n",
      "job: 41\n",
      "job: 42\n",
      "job: 43\n",
      "job: 44\n",
      "job: 45\n",
      "job: 46\n",
      "job: 47\n",
      "job: 48\n",
      "job: 49\n",
      "job: 50\n",
      "job: 51\n",
      "job: 52\n",
      "job: 53\n",
      "job: 54\n",
      "job: 55\n",
      "job: 56\n",
      "job: 57\n",
      "job: 58\n",
      "job: 59\n",
      "job: 60\n",
      "job: 61\n",
      "job: 62\n",
      "job: 63\n",
      "job: 64\n",
      "job: 65\n",
      "job: 66\n",
      "job: 67\n",
      "job: 68\n",
      "job: 69\n",
      "job: 70\n",
      "job: 71\n",
      "job: 72\n",
      "job: 73\n",
      "job: 74\n",
      "job: 75\n",
      "job: 76\n",
      "job: 77\n",
      "job: 78\n",
      "job: 79\n",
      "job: 80\n",
      "job: 81\n",
      "job: 82\n",
      "job: 83\n",
      "job: 84\n",
      "job: 85\n",
      "job: 86\n",
      "job: 87\n",
      "job: 88\n",
      "job: 89\n",
      "job: 90\n",
      "job: 91\n",
      "job: 92\n",
      "job: 93\n",
      "job: 94\n",
      "job: 95\n",
      "job: 96\n",
      "job: 97\n",
      "job: 98\n",
      "job: 99\n",
      "job: 100\n",
      "job: 101\n",
      "job: 102\n",
      "job: 103\n",
      "job: 104\n",
      "job: 105\n",
      "job: 106\n",
      "job: 107\n",
      "job: 108\n",
      "job: 109\n",
      "job: 110\n",
      "job: 111\n",
      "job: 112\n",
      "job: 113\n",
      "job: 114\n",
      "job: 115\n",
      "job: 116\n",
      "job: 117\n",
      "job: 118\n",
      "job: 119\n",
      "job: 120\n",
      "job: 121\n",
      "job: 122\n",
      "job: 123\n",
      "job: 124\n",
      "job: 125\n",
      "job: 126\n",
      "job: 127\n",
      "job: 128\n",
      "job: 129\n",
      "job: 130\n",
      "job: 131\n",
      "job: 132\n",
      "job: 133\n",
      "job: 134\n",
      "job: 135\n",
      "job: 136\n",
      "job: 137\n",
      "job: 138\n",
      "job: 139\n",
      "job: 140\n",
      "job: 141\n",
      "job: 142\n",
      "job: 143\n",
      "job: 144\n",
      "job: 145\n",
      "job: 146\n",
      "job: 147\n",
      "job: 148\n",
      "job: 149\n",
      "job: 150\n",
      "job: 151\n",
      "job: 152\n",
      "job: 153\n",
      "job: 154\n",
      "job: 155\n",
      "job: 156\n",
      "job: 157\n",
      "job: 158\n",
      "job: 159\n",
      "job: 160\n",
      "job: 161\n",
      "job: 162\n",
      "job: 163\n",
      "job: 164\n",
      "job: 165\n",
      "job: 166\n",
      "job: 167\n",
      "job: 168\n",
      "job: 169\n",
      "job: 170\n",
      "job: 171\n",
      "job: 172\n",
      "job: 173\n",
      "job: 174\n",
      "job: 175\n",
      "job: 176\n",
      "job: 177\n",
      "job: 178\n",
      "job: 179\n",
      "job: 180\n",
      "job: 181\n",
      "job: 182\n",
      "job: 183\n",
      "job: 184\n",
      "job: 185\n",
      "job: 186\n",
      "job: 187\n",
      "job: 188\n",
      "job: 189\n",
      "job: 190\n",
      "job: 191\n",
      "job: 192\n",
      "job: 193\n",
      "job: 194\n",
      "job: 195\n",
      "job: 196\n",
      "job: 197\n",
      "job: 198\n",
      "job: 199\n",
      "vacuum_dg: -49.321429301137755, ddg: 0.07415987291604975\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prep work arrays (from distributed jobs) and call analyze()\n",
    "d_results = {}\n",
    "for i in tqdm_notebook([18]):\n",
    "    print(f\"dir: {i}\")\n",
    "    # Load and combine arrays\n",
    "    forward_solvent_arrays = []\n",
    "    reverse_solvent_arrays = []\n",
    "    forward_vacuum_arrays = []\n",
    "    reverse_vacuum_arrays = []\n",
    "    for j in range(200):\n",
    "        print(f\"job: {j}\")\n",
    "        forward_solvent_path = f'/data/chodera/zhangi/perses_benchmark/neq/7/{i}/{i}_solvent_{j}_forward.npy'\n",
    "        reverse_solvent_path = f'/data/chodera/zhangi/perses_benchmark/neq/7/{i}/{i}_solvent_{j}_reverse.npy'\n",
    "        forward_vacuum_path = f'/data/chodera/zhangi/perses_benchmark/neq/7/{i}/{i}_vacuum_{j}_forward.npy'\n",
    "        reverse_vacuum_path = f'/data/chodera/zhangi/perses_benchmark/neq/7/{i}/{i}_vacuum_{j}_reverse.npy'\n",
    "        if os.path.exists(forward_solvent_path):\n",
    "            with open(forward_solvent_path, 'rb') as f:\n",
    "                forward_solvent_arrays.append(np.load(f))\n",
    "        if os.path.exists(reverse_solvent_path):\n",
    "            with open(reverse_solvent_path, 'rb') as f:\n",
    "                reverse_solvent_arrays.append(np.load(f))\n",
    "        if os.path.exists(forward_vacuum_path):\n",
    "            with open(forward_vacuum_path, 'rb') as f:\n",
    "                forward_vacuum_arrays.append(np.load(f))\n",
    "        if os.path.exists(reverse_vacuum_path):\n",
    "            with open(reverse_vacuum_path, 'rb') as f:\n",
    "                reverse_vacuum_arrays.append(np.load(f))\n",
    "    if forward_solvent_arrays and reverse_solvent_arrays and forward_vacuum_arrays and reverse_vacuum_arrays:\n",
    "#     if forward_vacuum_arrays and reverse_vacuum_arrays:\n",
    "        forward_solvent_combined = np.concatenate(forward_solvent_arrays)\n",
    "        forward_solvent_combined = np.array([cycle[0::10] for cycle in forward_solvent_combined])\n",
    "        reverse_solvent_combined = np.concatenate(reverse_solvent_arrays)\n",
    "        reverse_solvent_combined = np.array([cycle[0::10] for cycle in reverse_solvent_combined])\n",
    "        \n",
    "        \n",
    "        forward_vacuum_combined = np.concatenate(forward_vacuum_arrays)\n",
    "        forward_vacuum_accumulated = np.array([cycle[-1] - cycle[0] for cycle in forward_vacuum_combined]) # compute this separately bc the last value of the subsampled array is diff than the actual last sample\n",
    "#         forward_vacuum_combined = np.array([cycle[0::10] for cycle in forward_vacuum_combined])\n",
    "\n",
    "        reverse_vacuum_combined = np.concatenate(reverse_vacuum_arrays)\n",
    "        reverse_vacuum_accumulated = np.array([cycle[-1] - cycle[0] for cycle in reverse_vacuum_combined]) # compute this separately bc the last value of the subsampled array is diff than the actual last sample\n",
    "#         reverse_vacuum_combined = np.array([cycle[0::10] for cycle in reverse_vacuum_combined])\n",
    "        \n",
    "        # Analyze\n",
    "        solvent_dg, solvent_ddg = analyze(forward_solvent_combined, reverse_solvent_combined, forward_solvent_accumulated, reverse_solvent_accumulated, i, 'solvent', os.path.dirname(forward_solvent_path))\n",
    "        vacuum_dg, vacuum_ddg = analyze(forward_vacuum_combined, reverse_vacuum_combined, forward_vacuum_accumulated, reverse_vacuum_accumulated, i, \"THR->ALA\", 'vacuum', os.path.dirname(forward_vacuum_path))\n",
    "        solvation_dg = vacuum_dg - solvent_dg\n",
    "        solvation_ddg = (vacuum_ddg**2 + solvent_ddg**2)**0.5\n",
    "        d_results[pairs[i]] = [solvation_dg, solvation_ddg]\n",
    "#         print(f\"vacuum_dg: {vacuum_dg}, ddg: {vacuum_ddg}\")\n",
    "\n",
    "#         print(f\"vacuum dg: {vacuum_dg}, solvent_dg: {solvent_dg}\")\n",
    "    else:\n",
    "        print(f\"dir {i} has at least one phase without data\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_vacuum_path = '/data/chodera/zhangi/perses_benchmark/neq/7/7/7_vacuum_0_forward.npy'\n",
    "with open(forward_vacuum_path, 'rb') as f:\n",
    "    array = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.0032781 , 0.00657016, ...,        nan,        nan,\n",
       "               nan]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangi/miniconda3/envs/perses-sims/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723fd561bf444b748372ed2c6796a269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: 9\n",
      "job: 0\n",
      "job: 1\n",
      "job: 2\n",
      "job: 3\n",
      "job: 4\n",
      "job: 5\n",
      "job: 6\n",
      "job: 7\n",
      "job: 8\n",
      "job: 9\n",
      "job: 10\n",
      "job: 11\n",
      "job: 12\n",
      "job: 13\n",
      "job: 14\n",
      "job: 15\n",
      "job: 16\n",
      "job: 17\n",
      "job: 18\n",
      "job: 19\n",
      "job: 20\n",
      "job: 21\n",
      "job: 22\n",
      "job: 23\n",
      "job: 24\n",
      "job: 25\n",
      "job: 26\n",
      "job: 27\n",
      "job: 28\n",
      "job: 29\n",
      "job: 30\n",
      "job: 31\n",
      "job: 32\n",
      "job: 33\n",
      "job: 34\n",
      "job: 35\n",
      "job: 36\n",
      "job: 37\n",
      "job: 38\n",
      "job: 39\n",
      "job: 40\n",
      "job: 41\n",
      "job: 42\n",
      "job: 43\n",
      "job: 44\n",
      "job: 45\n",
      "job: 46\n",
      "job: 47\n",
      "job: 48\n",
      "job: 49\n",
      "job: 50\n",
      "job: 51\n",
      "job: 52\n",
      "job: 53\n",
      "job: 54\n",
      "job: 55\n",
      "job: 56\n",
      "job: 57\n",
      "job: 58\n",
      "job: 59\n",
      "job: 60\n",
      "job: 61\n",
      "job: 62\n",
      "job: 63\n",
      "job: 64\n",
      "job: 65\n",
      "job: 66\n",
      "job: 67\n",
      "job: 68\n",
      "job: 69\n",
      "job: 70\n",
      "job: 71\n",
      "job: 72\n",
      "job: 73\n",
      "job: 74\n",
      "job: 75\n",
      "job: 76\n",
      "job: 77\n",
      "job: 78\n",
      "job: 79\n",
      "job: 80\n",
      "job: 81\n",
      "job: 82\n",
      "job: 83\n",
      "job: 84\n",
      "job: 85\n",
      "job: 86\n",
      "job: 87\n",
      "job: 88\n",
      "job: 89\n",
      "job: 90\n",
      "job: 91\n",
      "job: 92\n",
      "job: 93\n",
      "job: 94\n",
      "job: 95\n",
      "job: 96\n",
      "job: 97\n",
      "job: 98\n",
      "job: 99\n",
      "vacuum_dg: -47.47230410221346, ddg: 0.09503482556089331\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prep work arrays (from distributed jobs) and call analyze()\n",
    "d_results = {}\n",
    "for i in tqdm_notebook(['9']):\n",
    "    print(f\"dir: {i}\")\n",
    "    # Load and combine arrays\n",
    "    forward_solvent_arrays = []\n",
    "    reverse_solvent_arrays = []\n",
    "    forward_vacuum_arrays = []\n",
    "    reverse_vacuum_arrays = []\n",
    "    for j in range(100):\n",
    "        print(f\"job: {j}\")\n",
    "        forward_solvent_path = f'/data/chodera/zhangi/perses_benchmark/neq/3/{i}/{i}_solvent_{j}_forward.npy'\n",
    "        reverse_solvent_path = f'/data/chodera/zhangi/perses_benchmark/neq/3/{i}/{i}_solvent_{j}_reverse.npy'\n",
    "        forward_vacuum_path = f'/data/chodera/zhangi/perses_benchmark/neq/3/{i}/{i}_vacuum_{j}_forward.npy'\n",
    "        reverse_vacuum_path = f'/data/chodera/zhangi/perses_benchmark/neq/3/{i}/{i}_vacuum_{j}_reverse.npy'\n",
    "        if os.path.exists(forward_solvent_path):\n",
    "            with open(forward_solvent_path, 'rb') as f:\n",
    "                forward_solvent_arrays.append(np.load(f))\n",
    "        if os.path.exists(reverse_solvent_path):\n",
    "            with open(reverse_solvent_path, 'rb') as f:\n",
    "                reverse_solvent_arrays.append(np.load(f))\n",
    "        if os.path.exists(forward_vacuum_path):\n",
    "            with open(forward_vacuum_path, 'rb') as f:\n",
    "                forward_vacuum_arrays.append(np.load(f))\n",
    "        if os.path.exists(reverse_vacuum_path):\n",
    "            with open(reverse_vacuum_path, 'rb') as f:\n",
    "                reverse_vacuum_arrays.append(np.load(f))\n",
    "#     if forward_solvent_arrays and reverse_solvent_arrays and forward_vacuum_arrays and reverse_vacuum_arrays:\n",
    "    if forward_vacuum_arrays and reverse_vacuum_arrays:\n",
    "#         forward_solvent_combined = np.concatenate(forward_solvent_arrays)\n",
    "#         forward_solvent_combined = np.array([cycle[0::10] for cycle in forward_solvent_combined])\n",
    "#         reverse_solvent_combined = np.concatenate(reverse_solvent_arrays)\n",
    "#         reverse_solvent_combined = np.array([cycle[0::10] for cycle in reverse_solvent_combined])\n",
    "        \n",
    "        \n",
    "        forward_vacuum_combined = np.concatenate(forward_vacuum_arrays)\n",
    "        forward_vacuum_accumulated = np.array([cycle[-1] - cycle[0] for cycle in forward_vacuum_combined]) # compute this separately bc the last value of the subsampled array is diff than the actual last sample\n",
    "#         forward_vacuum_combined = np.array([cycle[0::10] for cycle in forward_vacuum_combined])\n",
    "\n",
    "        reverse_vacuum_combined = np.concatenate(reverse_vacuum_arrays)\n",
    "        reverse_vacuum_accumulated = np.array([cycle[-1] - cycle[0] for cycle in reverse_vacuum_combined]) # compute this separately bc the last value of the subsampled array is diff than the actual last sample\n",
    "#         reverse_vacuum_combined = np.array([cycle[0::10] for cycle in reverse_vacuum_combined])\n",
    "        \n",
    "        # Analyze\n",
    "#         solvent_dg, solvent_ddg = analyze(forward_solvent_combined, reverse_solvent_combined, forward_solvent_accumulated, reverse_solvent_accumulated, i, 'solvent', os.path.dirname(forward_solvent_path))\n",
    "        vacuum_dg, vacuum_ddg = analyze(forward_vacuum_combined, reverse_vacuum_combined, forward_vacuum_accumulated, reverse_vacuum_accumulated, 9, 'vacuum', os.path.dirname(forward_vacuum_path))\n",
    "#         solvation_dg = vacuum_dg - solvent_dg\n",
    "#         solvation_ddg = (vacuum_ddg**2 + solvent_ddg**2)**0.5\n",
    "#         d_results[pairs[i]] = [solvation_dg, solvation_ddg]\n",
    "        print(f\"vacuum_dg: {vacuum_dg}, ddg: {vacuum_ddg}\")\n",
    "\n",
    "#         print(f\"vacuum dg: {vacuum_dg}, solvent_dg: {solvent_dg}\")\n",
    "    else:\n",
    "        print(f\"dir {i} has at least one phase without data\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
